{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = './data/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar10_validation = datasets.CIFAR10(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0, 3:1}\n",
    "class_names = ['airplane', 'cat']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0,3]]\n",
    "cifar2_validation = [(img, label_map[label]) for img, label in cifar10_validation if label in [0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "img, label = cifar2[10]\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()\n",
    "print(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlockPlain(nn.Module):\n",
    "    def __init__(self, input_channels, channel_factor=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.channel_factor = channel_factor\n",
    "        self.stride = stride\n",
    "\n",
    "        out_channels = input_channels * channel_factor\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3, padding=1, stride=stride\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3, padding=1, stride=1\n",
    "        )\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "\n",
    "        if stride != 1:\n",
    "            self.downsample = nn.MaxPool2d(stride,stride)\n",
    "        if channel_factor != 1:\n",
    "            self.cut = self.shortcut(input_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.stride != 1:\n",
    "            x = self.downsample(x)\n",
    "        if self.channel_factor != 1:\n",
    "            x = self.cut(x)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "    def shortcut(self, input_channels, output_channels):\n",
    "        return nn.Conv2d(input_channels, output_channels, kernel_size=1, padding=0)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_channels, channel_factor, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.channel_factor = channel_factor\n",
    "        self.stride = stride\n",
    "\n",
    "        first_out_channels = input_channels * channel_factor // 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_channels, \n",
    "            first_out_channels,\n",
    "            kernel_size=1, padding=0, stride=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(first_out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            first_out_channels, \n",
    "            first_out_channels,\n",
    "            kernel_size=3, padding=1, stride=stride\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(first_out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            first_out_channels, \n",
    "            first_out_channels * 4,\n",
    "            kernel_size=1, padding=0, stride=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(first_out_channels * 4)\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=1, stride=stride)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "        torch.nn.init.kaiming_normal_(self.conv3.weight, nonlinearity=\"relu\")\n",
    "        torch.nn.init.zeros_(self.bn1.bias)\n",
    "        torch.nn.init.zeros_(self.bn2.bias)\n",
    "        torch.nn.init.zeros_(self.bn3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.channel_factor > 1:\n",
    "            mapping = torch.zeros_like(out)\n",
    "            mapping[:,:x.shape[1],:,:] = self.downsample(x)\n",
    "            out += mapping\n",
    "        else:\n",
    "            out += x\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1, stride=2)\n",
    "        self.resblocks1 = nn.Sequential(\n",
    "            *(6 * [ResBlockPlain(32)])\n",
    "        )\n",
    "        self.resblocks2 = ResBlockPlain(32, 2, stride=2)\n",
    "        self.resblocks3 = nn.Sequential(\n",
    "            *(8 * [ResBlockPlain(64, 1)])\n",
    "        )\n",
    "        self.resblocks4 = ResBlockPlain(64, 2, stride=2)\n",
    "        self.resblocks5 = nn.Sequential(\n",
    "            *(8 * [ResBlockPlain(128, 1)])\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4*4*128, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        # out = self.pool1(out)\n",
    "        # out = F.max_pool2d(out, 2)\n",
    "        out = self.resblocks1(out)\n",
    "        out = self.resblocks2(out)\n",
    "        out = self.resblocks3(out)\n",
    "        out = self.resblocks4(out)\n",
    "        out = self.resblocks5(out)\n",
    "        flatten = nn.Flatten()\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs: int, optimizer, model, loss_fn, train_loader, validate_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "\n",
    "            print(f\"{datetime.datetime.now()} Epoch {epoch}: Training loss {loss_train / len(train_loader)}\")\n",
    "            validate(model, train_loader, validate_loader)\n",
    "\n",
    "def validate(model, train_loader, validate_loader):\n",
    "    model.eval()\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", validate_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels\n",
    "                outputs = model(imgs).cpu()\n",
    "                predicted = np.argmax(outputs.numpy(), axis=1)\n",
    "                total += labels.shape[0]\n",
    "\n",
    "                correct += int((predicted == labels.numpy()).sum())\n",
    "\n",
    "            print(f\"{name} acc: {correct / total:.3f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-16 03:37:14.805626 Epoch 1: Training loss 177.347396504879\n",
      "train acc: 0.652\n",
      "val acc: 0.652\n",
      "2022-05-16 03:37:21.476997 Epoch 5: Training loss 0.40984014198184016\n",
      "train acc: 0.831\n",
      "val acc: 0.827\n",
      "2022-05-16 03:37:29.734540 Epoch 10: Training loss 0.3345222719013691\n",
      "train acc: 0.856\n",
      "val acc: 0.838\n",
      "2022-05-16 03:37:38.006441 Epoch 15: Training loss 0.27099907025694847\n",
      "train acc: 0.903\n",
      "val acc: 0.849\n",
      "2022-05-16 03:37:46.249940 Epoch 20: Training loss 0.23350703790783883\n",
      "train acc: 0.926\n",
      "val acc: 0.856\n",
      "2022-05-16 03:37:54.567007 Epoch 25: Training loss 0.20084048695862294\n",
      "train acc: 0.928\n",
      "val acc: 0.856\n",
      "2022-05-16 03:38:02.788665 Epoch 30: Training loss 0.18028815612196922\n",
      "train acc: 0.944\n",
      "val acc: 0.860\n",
      "2022-05-16 03:38:11.000281 Epoch 35: Training loss 0.1882568622007966\n",
      "train acc: 0.957\n",
      "val acc: 0.859\n",
      "2022-05-16 03:38:19.251253 Epoch 40: Training loss 0.0938527244143188\n",
      "train acc: 0.941\n",
      "val acc: 0.845\n",
      "2022-05-16 03:38:27.510642 Epoch 45: Training loss 0.041305905138142404\n",
      "train acc: 0.913\n",
      "val acc: 0.821\n",
      "2022-05-16 03:38:35.711420 Epoch 50: Training loss 0.07163531666737981\n",
      "train acc: 0.948\n",
      "val acc: 0.843\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=256, shuffle=True)\n",
    "validate_loader = torch.utils.data.DataLoader(cifar2_validation, batch_size=256, shuffle=False)\n",
    "\n",
    "model = NetResDeep().to(device=device)\n",
    "if device == \"cuda\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "# model = Net().to(device=device)\n",
    "# model.load_state_dict(torch.load(data_path + \"cifar2_res.pt\"))\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=50,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    validate_loader=validate_loader\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), data_path + \"cifar2_res.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
